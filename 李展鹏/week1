import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt



class Model(nn.Module):
    def __init__(self, input_size, output_size):
        super(Model, self).__init__()
        self.Linear = nn.Linear(input_size, 3)
        self.loss = nn.CrossEntropyLoss()  #使用交叉熵算法

    def forward(self, x,y=None):
        y_pred = self.Linear(x)
        if y is not None:
            return self.loss(y_pred, y)
        else:
            return y_pred

def build_sample():
    x=np.random.random(3)
    max_index=np.argmax(x)
    if max_index==0:
        return x,0
    elif max_index==1:
        return x,1
    elif max_index==2:
        return x,2

#随机生成样本
def build_dataset(total_sample):
    X=[]
    Y=[]
    for i in range(total_sample):
        x,y=build_sample()
        X.append(x)
        Y.append(y)
    return torch.FloatTensor(X), torch.LongTensor(Y)
#测试代码
def evaluate(model):
    model.eval()
    test_sample=100
    x,y=build_dataset(test_sample)
    correct , wrong=0
    with torch.no_grad():
        y_pred=model(x,y)  #模型预测
        for y_p,y_t in zip(y_pred,y):  #与真实标签进行对比
            if torch.argmax(y_p) == int(y_t):
                correct +=1
            else:
                wrong+=1
    print("正确预测个数：%d，正确率：%f" %(correct , correct/(correct+wrong)))
    return correct/(correct+wrong)
def main():
    epochs=100
    batch_size=50
    train_sample=10000
    input_size=3
    learning_rate=0.001
    model=Model(input_size,3)
    optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)
    log=[]
    train_x,train_y=build_dataset(train_sample)
    for epoch in range(epochs):
        model.train()
        watch_loss=[]
        for batch_index in range(train_sample//batch_size):
            x = train_x[batch_index*batch_size:(batch_index+1)*batch_size]
            y = train_y[batch_index*batch_size:(batch_index+1)*batch_size]
            loss=model(x,y)
            loss.backward()
            optimizer.step()    #更新权重
            optimizer.zero_grad()       #权重归零
            watch_loss.append(loss.item())
        print("==\n第%d轮平均loss：%f" %(epoch,np.mean(watch_loss)))
        acc=evaluate(model)     #测试模型的结果
        log.append([acc,float(np.mean(watch_loss))])
    torch.save(model.state_dict(),'modelwork1.pt')
    print(log)
    plt.plot(range(len(log)),[l[0] for l in log], label="acc")
    plt.plot(range(len(log)),[l[1] for l in log], label="loss")
    plt.legend()
    plt.show()
    return
def predict(model_path,input_vec):
    input_size=3
    model=Model(input_size)
    model.load_state_dict(torch.load(model_path))
    print(model.state_dict())

    model.eval()
    with torch.no_grad():   #不计算梯度
        result=model.forward(torch.from_numpy(input_vec))
    for vec,res in zip(input_vec,result):
        print("输入：%s, 预测类别：%s, 概率值：%s" % (vec, torch.argmax(res), res))  # 打印结果

if __name__=="__main__":
    main()
    # test_vec=[1,2,3]
    # predict("model.pt",test_vec)





